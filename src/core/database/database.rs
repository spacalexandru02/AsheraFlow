use std::fs::{self, File};
use std::io::Write;
use std::path::{Path, PathBuf};
use sha1::{Digest, Sha1};
use flate2::write::ZlibEncoder;
use flate2::Compression;
use crate::core::index::index::Index;
use crate::core::workspace::Workspace;
use crate::errors::error::Error;
use std::io::Read;

pub struct Database {
    pub pathname: PathBuf,
    temp_chars: Vec<char>,
}

pub trait GitObject {
    fn get_type(&self) -> &str;
    fn to_bytes(&self) -> Vec<u8>;
    fn set_oid(&mut self, oid: String);
}

impl Database {
    pub fn verify_repository_integrity(self, root_path: &Path) -> Result<(), Error> {
        println!("\n========== VERIFICARE INTEGRITATE REPOSITORY ==========");
        
        let git_path = root_path.join(".ash");
        let db_path = git_path.join("objects");
        let index_path = git_path.join("index");
        
        // VerificƒÉ existen»õa structurii de directoare
        if !git_path.exists() {
            return Err(Error::Generic(format!("Repository path does not exist: {}", git_path.display())));
        }
        
        println!("1. Verificare structurƒÉ repository");
        for dir in ["objects", "refs"] {
            let dir_path = git_path.join(dir);
            if !dir_path.exists() {
                println!("‚ùå Directorul {} nu existƒÉ", dir_path.display());
            } else {
                println!("‚úÖ Directorul {} existƒÉ", dir_path.display());
            }
        }
        
        // Ini»õializeazƒÉ componentele
        let database = Database::new(db_path);
        let mut index = Index::new(&index_path);
        
        // VerificƒÉ indexul
        println!("\n2. Verificare index");
        match File::open(&index_path) {
            Ok(_) => println!("‚úÖ Fi»ôierul index existƒÉ"),
            Err(_) => {
                println!("‚ùå Fi»ôierul index nu existƒÉ");
                return Err(Error::Generic("Index file does not exist".to_string()));
            }
        }
        
        let mut index_valid = true;
        
        // √éncarcƒÉ indexul
        match index.load() {
            Ok(_) => println!("‚úÖ Indexul a fost √ÆncƒÉrcat cu succes"),
            Err(e) => {
                println!("‚ùå Eroare la √ÆncƒÉrcarea indexului: {}", e);
                index_valid = false;
            }
        }
        
        // VerificƒÉ numƒÉrul de intrƒÉri
        if index_valid {
            let entry_count = index.entries.len();
            println!("üìä Indexul con»õine {} intrƒÉri", entry_count);
            
            // VerificƒÉ fiecare intrare
            println!("\n3. Verificare intrƒÉri √Æn index");
            
            for (i, entry) in index.each_entry().enumerate() {
                println!("\nIntrarea #{}: {}", i+1, entry.path);
                println!("   OID: {}", entry.oid);
                println!("   Mod: {} ({})", entry.mode, entry.mode_octal());
                
                // VerificƒÉ existen»õa obiectului
                if database.exists(&entry.oid) {
                    println!("   ‚úÖ Obiectul existƒÉ √Æn baza de date");
                    
                    // VerificƒÉ integritatea obiectului
                    match verify_object_content(&database, &entry.oid) {
                        Ok(_) => println!("   ‚úÖ Con»õinutul obiectului este valid"),
                        Err(e) => println!("   ‚ùå Eroare la verificarea con»õinutului: {}", e)
                    }
                } else {
                    println!("   ‚ùå Obiectul nu existƒÉ √Æn baza de date");
                    index_valid = false;
                }
                
                // VerificƒÉ cƒÉ calea fi»ôierului existƒÉ √Æn workspace
                let workspace_path = root_path.join(&entry.path);
                if workspace_path.exists() {
                    println!("   ‚úÖ Fi»ôierul existƒÉ √Æn workspace");
                    
                    // VerificƒÉ cƒÉ hash-ul fi»ôierului actual se potrive»ôte cu cel din index
                    match verify_file_hash(&workspace_path, &entry.oid) {
                        Ok(true) => println!("   ‚úÖ Hash-ul fi»ôierului se potrive»ôte cu cel din index"),
                        Ok(false) => {
                            println!("   ‚ùå Hash-ul fi»ôierului NU se potrive»ôte cu cel din index");
                            index_valid = false;
                        },
                        Err(e) => println!("   ‚ùå Eroare la calculul hash-ului: {}", e)
                    }
                } else {
                    println!("   ‚ùå Fi»ôierul nu existƒÉ √Æn workspace");
                    index_valid = false;
                }
            }
        }
        
        // VerificƒÉ trecerea inversƒÉ: fi»ôiere din workspace care ar trebui sƒÉ fie √Æn index
        println!("\n4. CƒÉutare fi»ôiere neindexate");
        let workspace = Workspace::new(root_path);
        match workspace.list_files() {
            Ok(files) => {
                let mut untracked_files = Vec::new();
                
                for file in files {
                    let file_path = file.to_string_lossy().to_string();
                    if !index.entries.contains_key(&file_path) {
                        untracked_files.push(file_path);
                    }
                }
                
                if untracked_files.is_empty() {
                    println!("‚úÖ Toate fi»ôierele din workspace sunt √Æn index");
                } else {
                    println!("‚ÑπÔ∏è Fi»ôiere neindexate ({}):", untracked_files.len());
                    for file in untracked_files.iter().take(10) {
                        println!("   - {}", file);
                    }
                    if untracked_files.len() > 10 {
                        println!("   ... »ôi √ÆncƒÉ {} fi»ôiere", untracked_files.len() - 10);
                    }
                }
            },
            Err(e) => println!("‚ùå Eroare la listarea fi»ôierelor din workspace: {}", e)
        }
        
        // VerificƒÉ coheren»õa obiectelor din storage
        println!("\n5. Verificare coheren»õƒÉ obiecte");
        match audit_objects_storage(&database) {
            Ok(stats) => {
                println!("‚úÖ Verificare completƒÉ a bazei de date de obiecte");
                println!("   - Obiecte totale: {}", stats.0);
                println!("   - Obiecte blob: {}", stats.1);
                println!("   - Obiecte tree: {}", stats.2);
                println!("   - Obiecte commit: {}", stats.3);
            },
            Err(e) => println!("‚ùå Eroare la verificarea obiectelor: {}", e)
        }
        
        println!("\n========== REZULTAT FINAL ==========");
        if index_valid {
            println!("‚úÖ Repository-ul este √Æntr-o stare validƒÉ");
            Ok(())
        } else {
            println!("‚ùå Repository-ul are inconsisten»õe care necesitƒÉ rezolvare");
            Err(Error::Generic("Repository integrity check failed".to_string()))
        }

    }
    
    // Func»õie helper pentru a verifica con»õinutul unui obiect
    
    
    pub fn new(pathname: PathBuf) -> Self {
        let temp_chars: Vec<char> = ('a'..='z')
            .chain('A'..='Z')
            .chain('0'..='9')
            .collect();

        Database {
            pathname,
            temp_chars,
        }
    }

    pub fn exists(&self, oid: &str) -> bool {
        self.pathname.join(&oid[0..2]).join(&oid[2..]).exists()
    }

    pub fn store(&mut self, object: &mut impl GitObject) -> Result<(), Error> {
        let content = object.to_bytes();
        let header = format!("{} {}\0", object.get_type(), content.len());
        let mut full_content = header.as_bytes().to_vec();
        full_content.extend(content);

        let oid = Self::calculate_oid(&full_content);
        
        if !self.exists(&oid) {
            self.write_object(&oid, &full_content)?;
        }

        // Asigura»õi-vƒÉ cƒÉ `set_oid` este apelat √Æntotdeauna
        object.set_oid(oid.clone());

        Ok(())
    }

    fn calculate_oid(content: &[u8]) -> String {
        let mut hasher = Sha1::new();
        hasher.update(content);
        let result = hasher.finalize();
        format!("{:x}", result)
    }

    fn write_object(&self, oid: &str, content: &[u8]) -> Result<(), Error> {
        let object_path = self.pathname.join(&oid[0..2]).join(&oid[2..]);
        
        // Return early if object exists
        if object_path.exists() {
            return Ok(());
        }
        
        let dirname = object_path.parent().ok_or_else(|| {
            Error::Generic(format!("Invalid object path: {}", object_path.display()))
        })?;

        if !dirname.exists() {
            fs::create_dir_all(dirname)?;
        }

        let temp_name = self.generate_temp_name();
        let temp_path = dirname.join(temp_name);

        let mut file = File::create(&temp_path)?;

        // Compress and write
        let mut encoder = ZlibEncoder::new(Vec::new(), Compression::best());
        encoder.write_all(content)?;
        let compressed = encoder.finish()?;

        file.write_all(&compressed)?;
        fs::rename(temp_path, object_path)?;

        Ok(())
    }

    fn generate_temp_name(&self) -> String {
        use rand::seq::SliceRandom;
        let mut rng = rand::thread_rng();
        let name: String = (0..6)
            .map(|_| self.temp_chars.choose(&mut rng).unwrap())
            .collect();
        format!("tmp_obj_{}", name)
    }

    pub fn get_object_path(&self, oid: &str) -> PathBuf {
        self.pathname.join(&oid[0..2]).join(&oid[2..])
    }

    pub fn verify_object(&self, oid: &str) -> Result<(), Error> {
        println!("Verificare obiect: {}", oid);
        
        // VerificƒÉ dacƒÉ obiectul existƒÉ
        if !self.exists(oid) {
            return Err(Error::Generic(format!("Obiectul {} nu existƒÉ", oid)));
        }
        
        // √éncearcƒÉ sƒÉ cite»ôti obiectul
        let object_path = self.get_object_path(oid);
        let file = File::open(&object_path)?;
        
        // Decomprima obiectul
        let mut decoder = flate2::read::ZlibDecoder::new(file);
        let mut content = Vec::new();
        
        match decoder.read_to_end(&mut content) {
            Ok(size) => {
                println!("Obiect citit: {} bytes", size);
                
                // VerificƒÉ formatul obiectului
                let null_pos = content.iter().position(|&b| b == 0);
                if let Some(pos) = null_pos {
                    let header = String::from_utf8_lossy(&content[0..pos]);
                    println!("Header: {}", header);
                    
                    // VerificƒÉ dacƒÉ header-ul are formatul corect "<type> <size>"
                    let parts: Vec<&str> = header.split(' ').collect();
                    if parts.len() == 2 {
                        let obj_type = parts[0];
                        let obj_size: usize = parts[1].parse().unwrap_or(0);
                        
                        println!("Tip: {}, Dimensiune declaratƒÉ: {}", obj_type, obj_size);
                        println!("Dimensiune realƒÉ: {}", content.len() - pos - 1);
                        
                        // VerificƒÉ dacƒÉ dimensiunea declaratƒÉ se potrive»ôte cu cea realƒÉ
                        if obj_size == content.len() - pos - 1 {
                            println!("‚úì Dimensiunea se potrive»ôte");
                        } else {
                            println!("‚úó Dimensiunea nu se potrive»ôte");
                        }
                    } else {
                        println!("‚úó Format header invalid");
                    }
                } else {
                    println!("‚úó Nu s-a gƒÉsit byte-ul null separator √Æn header");
                }
                
                Ok(())
            },
            Err(e) => {
                Err(Error::Generic(format!("Eroare la decomprimarea obiectului: {}", e)))
            }
        }
    }

    
// Func»õie pentru a verifica cƒÉ hash-ul unui fi»ôier se potrive»ôte cu cel din index

}

pub fn verify_object_content(database: &Database, oid: &str) -> Result<(), Error> {
    let object_path = database.pathname.join(&oid[0..2]).join(&oid[2..]);
    let file = File::open(&object_path)?;
    
    let mut decoder = flate2::read::ZlibDecoder::new(file);
    let mut content = Vec::new();
    decoder.read_to_end(&mut content)?;
    
    let null_pos = content.iter().position(|&b| b == 0)
        .ok_or_else(|| Error::Generic("Invalid object format: missing null byte".to_string()))?;
    
    let header = String::from_utf8_lossy(&content[0..null_pos]).to_string();
    let parts: Vec<&str> = header.split(' ').collect();
    
    if parts.len() != 2 {
        return Err(Error::Generic(format!("Invalid header format: {}", header)));
    }
    
    let obj_type = parts[0];
    if !["blob", "tree", "commit"].contains(&obj_type) {
        return Err(Error::Generic(format!("Invalid object type: {}", obj_type)));
    }
    
    let obj_size: usize = parts[1].parse()
        .map_err(|_| Error::Generic(format!("Invalid size in header: {}", parts[1])))?;
    
    if obj_size != content.len() - null_pos - 1 {
        return Err(Error::Generic(format!(
            "Size mismatch: header claims {} bytes, actual content is {} bytes",
            obj_size, content.len() - null_pos - 1
        )));
    }
    
    Ok(())
}

pub fn verify_file_hash(file_path: &Path, expected_oid: &str) -> Result<bool, Error> {
    let data = fs::read(file_path)?;
    
    let header = format!("blob {}\0", data.len());
    let mut full_content = header.as_bytes().to_vec();
    full_content.extend(&data);
    
    let mut hasher = Sha1::new();
    hasher.update(&full_content);
    let result = hasher.finalize();
    let actual_oid = format!("{:x}", result);
    
    Ok(actual_oid == expected_oid)
}

// Func»õie pentru a audita √Æntreaga bazƒÉ de date de obiecte
// ReturneazƒÉ (total_obiecte, blob_count, tree_count, commit_count)
pub fn audit_objects_storage(database: &Database) -> Result<(usize, usize, usize, usize), Error> {
    let mut total_objects = 0;
    let mut blob_count = 0;
    let mut tree_count = 0;
    let mut commit_count = 0;
    
    let objects_dir = &database.pathname;
    for prefix_entry in fs::read_dir(objects_dir)? {
        let prefix_entry = prefix_entry?;
        let prefix_path = prefix_entry.path();
        
        if prefix_path.is_dir() && prefix_path.file_name().unwrap().len() == 2 {
            for obj_entry in fs::read_dir(&prefix_path)? {
                let obj_entry = obj_entry?;
                let obj_path = obj_entry.path();
                
                if obj_path.is_file() {
                    total_objects += 1;
                    
                    // DeterminƒÉ tipul obiectului
                    let prefix = prefix_path.file_name().unwrap().to_string_lossy();
                    let suffix = obj_path.file_name().unwrap().to_string_lossy();
                    let oid = format!("{}{}", prefix, suffix);
                    
                    let file = File::open(&obj_path)?;
                    let mut decoder = flate2::read::ZlibDecoder::new(file);
                    let mut content = Vec::new();
                    
                    match decoder.read_to_end(&mut content) {
                        Ok(_) => {
                            if let Some(null_pos) = content.iter().position(|&b| b == 0) {
                                let header = String::from_utf8_lossy(&content[0..null_pos]);
                                if header.starts_with("blob") {
                                    blob_count += 1;
                                } else if header.starts_with("tree") {
                                    tree_count += 1;
                                } else if header.starts_with("commit") {
                                    commit_count += 1;
                                }
                            }
                        },
                        Err(e) => {
                            println!("   ‚ö†Ô∏è Nu s-a putut citi obiectul {}: {}", oid, e);
                        }
                    }
                }
            }
        }
    }
    
    Ok((total_objects, blob_count, tree_count, commit_count))
}